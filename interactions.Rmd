---
title: "Twitter Network Visualizations"
author: "Niel Schrage"
date: "4/28/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# loading libraries I always use. 
library(tidyverse)
library(dplyr)
library(knitr)
library(styler)
library(purrr)

library(rlist)

# loading libraries for graphics/display
library(ggplot2)
library(ggthemes)
library(patchwork)
library(GGally)
library(network)
library(sna)
library(RColorBrewer)
library(ggrepel)

# loading libraries for Twitter research -- need authorization for this one...  
# from what I'm reading online, it seems like rtweet is better
library(twitteR)

library(rjson)

# can I use this without a twitter account... apparently yes, well that gets rid of that problem...
# I might have spoken too soon here. looking at the lookup_friendship... need twitter authorization... oof... 
# consensus is better.. 

library(rtweet)

  # access to friends, followers, tweets, etcv

library(httr)

# oh geez this is going to be an adventure... 

# data collection
SF <- get_timelines(c("MattHaneySF", "AaronPeskin", "RafaelMandelman", "D4GordonMar", "DeanPreston", "SandraLeeFewer", "HillaryRonen", "Ahsha_Safai", "SupStefani", "shamannwalton", "NormanYeeSF", "LondonBreed"), n = 3200)



# as my application is being reviewed, it is probably a good idea to start laying out what the code actually will look like so I can hit the ground running as soon as I get the green light.

# maybe do a dry run with my own twitter network data... just to see if it is doable. 

# concerned that the things I'm seeing online don't exactly align with what my initial project description was... do I need to keep digging, or should I be thinking about reframing my project. 
```

# Introduction

```{r setting up twitter api with rtweet, echo = FALSE}

# Huge assist from matthew... 

# whatever name you assigned to your created app
appname <- "com.mschrage.cs50.pset6"

## api key (example below is not a real key)
key <- "OmNp5994gPojHOzpeH6JuHCEh"

## api secret (example below is not a real key)
secret <- "UtB6CPYA8WnPpRtIo3S3w03DAXYqSOXVoMnVzJ9wMjHWiN2Nq0"

# create token named "twitter_token"
twitter_token <- create_token(
  app = appname,
  consumer_key = key,
  consumer_secret = secret) 

#,
  #access_token = "403220845-1fwgr3vsXuYqfObhMYyQuI1DCprcO3QypgfoKW5O",
  #access_secret = "LGftHBxuShElCTpjY4psbrMOG8zSv8HWbuaxhwTkKNfRG")

```

```{r NO, echo = FALSE, results = "asis"}

# setting up twitter authorization 
# need account to be approved before I can do this...

# loading twitter data
  # does norman yee not have a twitter... how to deal with that. that is actually crazy to me...
  # should I be looking at pre/post quarantine tweets... time frame? 

bos <- c("MattHaneySF", "AaronPeskin", "RafaelMandelman", "D4GordonMar", "DeanPreston", "SandraLeeFewer", "HillaryRonen", "Ahsha_Safai", "SupStefani", "shamannwalton", "NormanYeeSF", "LondonBreed")

board <- lookup_users(bos)

t <- lookup_tweets(statuses = "MattHaneySF", parse = TRUE, token = twitter_token)

Haney_Peskin <- lookup_friendships(source = "MattHaneySF", target = "AaronPeskin")

# You will not be able to collect any data until you have acquired API credentials.
  # how can I get around this... 

Haney2 <- lookup_tweets(statuses = "MattHaneySF", parse = TRUE, token = twitter_token)




# Need to be creative. Found package that gets 



```

```{r data collection/cleaning, echo=FALSE}



bos <- c("MattHaneySF", "AaronPeskin", "RafaelMandelman", "D4GordonMar", "DeanPreston", "SandraLeeFewer", "HillaryRonen", "Ahsha_Safai", "SupStefani", "shamannwalton", "NormanYeeSF", "LondonBreed")

# data cleaning
SF <- SF %>% 
  select(screen_name, text, mentions_screen_name, is_retweet, retweet_text, hashtags, reply_to_screen_name, created_at)

# mentions network
mentions <- SF %>% 
  filter(mentions_screen_name %in% bos)



bos = tibble(bos)

nodes = bos

# edges <- mentions %>% 

# filter out mentions when sup mentions themselves... messes up the 



edges <- mentions %>% 
  # unclear if i needed this check
  #filter(screen_name != mentions_screen_name) %>% 
  select(screen_name, mentions_screen_name) %>% 
  rename(Source = screen_name) %>% 
  rename(Target = mentions_screen_name)

# Flatten worked

edges <- flatten(edges)

net = network(edges, matrix.type = "edgelist")

#x = data.frame(Twitter = network.vertex.names(net))
#x = merge(x, nodes, by = "Twitter", sort = FALSE)$Groupe
#net %v% "party" = as.character(x)

# adding labels 

ggnet2(net, label = TRUE)

# initial graphic working

ggnet2(net, alpha = 0.75, size = 4, edge.alpha = 0.5, label = TRUE) 

# other things I could do 
  # weights -- edge weights... 
  # coloring by party ideology ... using thing in presentation 
  # scale by followers.










#mutate(mentions_screen_name = mentions_screen_name[[1]]) %>% 




#n = network()

#network.edgelist(mentions, n)


# example of code that works
r = "https://raw.githubusercontent.com/briatte/ggnet/master/"

# read nodes
v = read.csv(paste0(r, "inst/extdata/nodes.tsv"), sep = "\t")
names(v)
e = read.csv(paste0(r, "inst/extdata/network.tsv"), sep = "\t")
#names(e)
net = network(e, directed = TRUE)

# party affiliation
x = data.frame(Twitter = network.vertex.names(net))
x = merge(x, v, by = "Twitter", sort = FALSE)$Groupe
net %v% "party" = as.character(x)

# color palette
y = RColorBrewer::brewer.pal(9, "Set1")[ c(3, 1, 9, 6, 8, 5, 2) ]
names(y) = levels(x)

# network plot
ggnet2(net, color = "party", palette = y, alpha = 0.75, size = 4, edge.alpha = 0.5)

# retweet network

# overall interations -- not sure what to do here... 

###########################################################################################################

# basic retweet look up 
retweet <- SF %>% 
  filter(is_retweet == TRUE) %>% 
  filter(mentions_screen_name %in% c("MattHaneySF"))

sups <- c("MattHaneySF", "AaronPeskin", "RafaelMandelman", "D4GordonMar", "DeanPreston", "SandraLeeFewer", "HillaryRonen", "Ahsha_Safai", "SupStefani", "shamannwalton", "NormanYeeSF", "LondonBreed")


follower <- c(13040,)

containsSupHandle <-
  function(mentions) {
    length(intersect(mentions, sups)) >= 1
  }

retweet <- retweet %>% 
  mutate(new_col = map(mentions_screen_name, containsSupHandle)) %>% 
  filter(new_col == TRUE) %>% 
  select(screen_name, mentions_screen_name)

#datalist = list()

rng <- c(1:length(retweet$screen_name))

datalist <- map(rng, function(i) {
    handle <- retweet[[1]][i]
    mentions <- retweet[2][[1]][[i]] 
    
    matches <- map(mentions, function(tag) {
       if (tag %in% sups){
        list(handle,tag) 
       }
    }) 
    
   plyr::compact(matches)
})



datalist <- as_tibble(datalist)

datalist <- flatten(datalist)

datalist <- unlist(datalist)
datalist <- tibble(datalist)

net = network(dl_final, matrix.type = "edgelist", directed = TRUE)

#x = data.frame(Twitter = network.vertex.names(net))
#x = merge(x, nodes, by = "Twitter", sort = FALSE)$Groupe
#net %v% "party" = as.character(x)

# adding labels 

ggnet2(net, label = TRUE)

# initial graphic working

ggnet2(net, alpha = 0.75, size = 4, edge.alpha = 0.5, label = TRUE) 

# need to turn into a tibble officially

# for even rows

dl_even <- dl %>% 
  filter(row_number() %% 2 == 0) %>% 
  rename(Source = dl)

# for odd rows 
dl_odd <- dl %>% 
  filter(row_number() %% 2 == 1) %>% 
  rename(Target = dl)

# WOW THAT WAS HARD! 

nrow(distinct(dl_final, Source, Target))

# THIS FINISHES THE DATA SET FOR THE RETWEETS NETWORK

dl_final <- tibble(dl_odd, dl_even) 

dl_final$ID = paste(dl_final$Source, "/", dl_final$Target) 
dl_final

dl_weights <- dl_final %>% 
  group_by(ID) %>% 
  count(ID) %>% 
  rename(Weights = n) %>% 
  # why did I pick this number
  mutate(Weights = Weights/10) %>% 
  mutate(Source = strsplit(ID, " / ")[[1]][[1]]) %>% 
  mutate(Target = strsplit(ID, " / ")[[1]][[2]]) %>% 
  ungroup()

dl_weights <- dl_weights %>% 
  select(Source, Target, Weights, -ID)
  

# manually getting followers for weights
#c("MattHaneySF", "AaronPeskin", "RafaelMandelman", "D4GordonMar", "DeanPreston", "SandraLeeFewer", "HillaryRonen", "Ahsha_Safai", "SupStefani", "shamannwalton", "NormanYeeSF", "LondonBreed")

# getting follower... 

followers <- map(sups, function(handle) {
  get_followers(handle, n = 100000) %>% 
  nrow()
}) 

# <- flatten(dl_final)

net = network(dl_weights, matrix.type = "edgelist", directed = TRUE)

#set.edge.attribute(net, "weight", ifelse(net %e% "weights" > 0))

#x = data.frame(Twitter = network.vertex.names(net))
#x = merge(x, nodes, by = "Twitter", sort = FALSE)$Groupe
#net %v% "party" = as.character(x)

# adding labels 

#ggnet2(net, label = TRUE, )

# initial graphic working

ggnet2(net, alpha = 0.75, size = 1, edge.alpha = 0.5, label = TRUE, edge.size = dl_weights$Weights) 



###########################################################################################################


#i <- length(retweet$screen_name)
datalist = list()
i <- 8
#for (i in  length(retweet$screen_name)) {
    # ... make some data

    handle <- retweet[[1]][i]
    mentions <- retweet[2][[1]][[i]] 
    
      matches <- map(mentions, function(tag) {
       if (tag %in% sups){
        list(handle,tag) 
       }
      
    }) 
    
    print(matches)
    #lapply(matches, function(x) x[!is.null(x)])
    
    #matches <- plyr::compact(matches)
  
    
    #c(datalist, matches)
    
    #datalist <- datalist %>%  matches # add it to your list
    
    datalist <- append(datalist, matches)
    
   # datalist[[i]] <- c(datalist, matches)
#}





#big_data = do.call(rbind, datalist)
  

map(retweet,function(row) { length(intersect(row$mentions_screen_name, c("MattHaneySF", "AaronPeskin", "RafaelMandelman", "D4GordonMar", "DeanPreston", "SandraLeeFewer", "HillaryRonen", "Ahsha_Safai", "SupStefani", "shamannwalton", "NormanYeeSF", "LondonBreed"))) < 1 }) 



# need to get the duplicates... from the list. 
# what is the question we are trying to answer. for each element of a list, if that element exists within the nodes (later we will need to split it up, but not there... )


filter(mentions_screen_name %in% c("MattHaneySF", "AaronPeskin", "RafaelMandelman", "D4GordonMar", "DeanPreston", "SandraLeeFewer", "HillaryRonen", "Ahsha_Safai", "SupStefani", "shamannwalton", "NormanYeeSF", "LondonBreed"))

map(length(intersect(mentions_screen_name, c("MattHaneySF", "AaronPeskin", "RafaelMandelman", "D4GordonMar", "DeanPreston", "SandraLeeFewer", "HillaryRonen", "Ahsha_Safai", "SupStefani", "shamannwalton", "NormanYeeSF", "LondonBreed"))) < 1) 

write.csv(x = SF, file = "bosexport")
  
  
#retweet <- flatten(retweet) %>% 
  
  

write()
  


  
# hastags in common 

########################################################################################################

# need go start cleaning up code for methods section
# how to weight by followers/color

bos <- c("MattHaneySF", "AaronPeskin", "RafaelMandelman", "D4GordonMar", "DeanPreston", "SandraLeeFewer", "HillaryRonen", "Ahsha_Safai", "SupStefani", "shamannwalton", "NormanYeeSF", "LondonBreed")



```


```{r helpful tibble, echo = false}


# tibble about nodes 
# maybe helpful for doing weights I don't know... need to get these graphics asap... plus other information that may be helpful

# set up

bos_handle <- c("SandraLeeFewer", "SupStefani","AaronPeskin", "D4GordonMar", "DeanPreston", "MattHaneySF", "NormanYeeSF", "RafaelMandelman", "HillaryRonen", "shamannwalton", "Ahsha_Safai", "LondonBreed")

bos_district <- c("1", "2","3", "4", "5", "6", "7", "8", "9", "10", "11", "Mayor")

bos_ideo <- c("7", "19","1", "3", "3", "6", "8", "9", "6", "7", "16", "15")

bos_ideo <- as.numeric(bos_ideo)

bos_followers <- c("5000", "4000","8000", "1000", "6000", "13000", "6500", "4000", "8000", "4000", "2500", "77000")

bos_followers <- as.numeric(bos_followers)

bos_followers_scaled <- c("5", "4","8", "1", "6", "13", "6.5", "4", "8", "4", "2", "20")

bos_followers_scaled <- as.numeric(bos_followers_scaled)

nodes_info <- tibble(bos_handle, bos_district, bos_ideo, bos_followers, bos_followers_scaled)

# basic cleaning for presentation

nodes_info <- nodes_info %>% 
  rename(Twitter_Handle = bos_handle) %>% 
  rename(District = bos_district) %>% 
  rename(Estimated_Ideology = bos_ideo) %>% 
  rename(Twitter_Followers = bos_followers) %>% 
  rename(Twitter_Followers_Scaled = bos_followers_scaled) 


nodes_info %>% kable()



```

```{r vizualizing_retweets, echo = false, results = "asis"}

# basic retweet look up 

# first just selecting only retweets
retweet <- SF %>% 
  filter(is_retweet == TRUE) 

# list of all the supervisors... change the order
sups <- c("SandraLeeFewer", "SupStefani","AaronPeskin", "D4GordonMar", "DeanPreston", "MattHaneySF", "NormanYeeSF", "RafaelMandelman", "HillaryRonen", "shamannwalton", "Ahsha_Safai", "LondonBreed")

# created new function that deals with the way the column mentions_screen_name
# is set up (a column of lists). this function iterates over the retweet dataset
# and compares it against the list of supervisors - taking the intersect of the
# two lists. if the result is greater than or equal to one that means there is
# at least one supervisor mentioned.
containsSupHandle <-
  function(mentions) {
    length(intersect(mentions, sups)) >= 1
  }

# running the function described above over the dataset, creating a new column
# as an indicator of a retweet, then just selecting the screen name and
# mentions.
retweet <- retweet %>% 
  mutate(new_col = map(mentions_screen_name, containsSupHandle)) %>% 
  filter(new_col == TRUE) %>% 
  select(screen_name, mentions_screen_name)

#datalist = list()

# creating a range of the entire dataset to use in the next function
rng <- c(1:length(retweet$screen_name))

# breaking up the column of lists to find the specific supervisor/supervisors
# mentioned in a specific tweet and saving them. should spend a little more time
# talking about this... mapping over each entry, using the [] to access specific
# items in the list. mapping over each list and seeing if it occurs in sups
# (because there could be multiple supervisors named)
datalist <- map(rng, function(i) {
    handle <- retweet[[1]][i]
    mentions <- retweet[2][[1]][[i]] 
    
    matches <- map(mentions, function(tag) {
       if (tag %in% sups){
        list(handle,tag) 
       }
    }) 
    
   plyr::compact(matches)
})

# something worth pointing out here, this adds another column for multiple superviors 

# using unlist to get datalist out of the awful/confusing form it was in. Now
# need a work around to get it out of being a single column. Since I spent so
# much time looking at the data, you start to notice trends, and I saw that all
# the even columns were actually the source data, and the odd columns were
# target. just a little data wrangling and ill be on my way. First convert to tibble.
dl <- unlist(datalist)
dl <- tibble(dl)
 
# for even rows
dl_even <- dl %>% 
  filter(row_number() %% 2 == 0) %>% 
  rename(Source = dl)

# for odd rows 
dl_odd <- dl %>% 
  filter(row_number() %% 2 == 1) %>% 
  rename(Target = dl)

# THIS FINISHES THE DATA SET FOR THE RETWEETS NETWORK
# join them together and you get a dataset to plot the network vizualization.

dl_final <- tibble(dl_odd, dl_even) 

# This could be where I called it, but I want to do more. I want to look at the
# frequency of different interactions, so I'll need to calculate the weights. I
# start doing that by creating a Source-Target ID column to and grouping and
# counting by number of occurances. Unsuprisingly the top results were all
# people mentioning themselves in a retweet -- what commonly happens when you do
# a thread if I'm not mistaken. But I'll include in the paper the 10 or so most
# common connections and see if it follows partisan lines.

dl_final$ID = paste(dl_final$Source, "/", dl_final$Target) 
dl_final

# grouped by then counted, renamed for ease of comprehension. mutated to create
# weights (10 is arbitrary, but seems to work in this instance). The I split up
# the ID column that I made previously back into source and target to get ready
# to do the network visualization.
dl_weights <- dl_final %>% 
  group_by(ID) %>% 
  count(ID) %>% 
  rename(Weights = n) %>% 
  # picked a number that would help illustrate the frequency
  mutate(Weights = Weights/10) %>% 
  mutate(Source = strsplit(ID, " / ")[[1]][[1]]) %>% 
  mutate(Target = strsplit(ID, " / ")[[1]][[2]]) %>% 
  ungroup()

# selecting what I'll need for viz. 
dl_weights <- dl_weights %>% 
  select(Source, Target, Weights, -ID)

# arranged weights highest to lowest. got rid of intances where a source and target were the same and then selected the top ten results to display. 
dl_weights_tibble <- dl_weights %>% 
  arrange(desc(Weights)) %>% 
  slice(9:18)
  

# setting up network viz

net = network(dl_weights, matrix.type = "edgelist", directed = TRUE)

# also trying to scale by node size
# node placement is done via the Fruchterman-Reingold force-directed algorithm, but can be changed

bos_handle <- c("SandraLeeFewer", "SupStefani","AaronPeskin", "D4GordonMar", "DeanPreston", "MattHaneySF", "NormanYeeSF", "RafaelMandelman", "HillaryRonen", "shamannwalton", "Ahsha_Safai", "LondonBreed")

bos_district <- c("1", "2","3", "4", "5", "6", "7", "8", "9", "10", "11", "Mayor")

bos_ideo <- c("7", "19","1", "3", "3", "6", "8", "9", "6", "7", "16", "15")

bos_ideo <- as.numeric(bos_ideo)

bos_followers <- c("5000", "4000","8000", "1000", "6000", "13000", "6500", "4000", "8000", "4000", "2500", "77000")

# London Breed (the Mayor of SF has way more twitter followers than anyone else... messing up the graphic, can still tell the correct narrative with out displaying the exact disparity)


# eventually move that back up to first chunk
# looked at net data and reordered nodes_info... now going to reload it and hope it works

nodes_info <- nodes_info %>% 
  slice(3, 11, 4, 5, 9, 12, 6, 7, 8, 1 , 10, 2)


# I'm worried that these are the wrong values, and that I'm just hard coding
# stuff in that isn't actually there. How can I look under the hood. Wait now I
# know there is a problem... look at Peskin -- I know he has high connections
# with breed and as the graphic currently shows that does not exist. Realized
# the solution, need to look at Net... does it ever change -- no based on number
# of connections?



retweet_network <- ggnet2(net, alpha = 0.75, node.label = nodes_info$Twitter_Handle, label.size = 3, label.color = "red", node.size = nodes_info$Twitter_Followers_Scaled, max_size = 20, node.color = nodes_info$Estimated_Ideology, palette = "Blues", edge.size = dl_weights$Weights, edge.alpha = 0.5, mode = "fruchtermanreingold") + guides(color = FALSE, size = FALSE)

retweet_network

# Another Interesting Viz 

retweet_circle <- ggnet2(net, alpha = 0.75, node.label = nodes_info$Twitter_Handle, label.size = 2.25, label.color = "black", label.alpha = 0.95, node.size = nodes_info$Twitter_Followers_Scaled, max_size = 15, node.color = nodes_info$Estimated_Ideology, palette = "Blues", edge.size = dl_weights$Weights, edge.alpha = 0.5, mode = "circle", fontface = "bold") + guides(color = FALSE, size = FALSE)

retweet_circle

ggsave(filename = "retweet_circle.png", plot = retweet_circle, )


# testing... this is how all of them should be presented... much more professional... 
# testing... this is too cool not to do something with it... 



  




```

```{r vizualizing_mentions, echo = false, results = "asis"}

```



